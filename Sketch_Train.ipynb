{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "M1=96\n",
    "K1=5\n",
    "S1=3\n",
    "\n",
    "G_LR = 0.0003\n",
    "D_LR = 0.0003\n",
    "BATCHSIZE = 90\n",
    "EPOCHES = 8000\n",
    "MAIN_PATH=\"./training2D/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs():\n",
    "    files = os.listdir(MAIN_PATH)\n",
    "    imgs = []\n",
    "    for file in files:\n",
    "        imgs.append(cv2.imread(MAIN_PATH + file,0))\n",
    "    print(\"get_imgs\")\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ws_bs(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        init.normal_(m.weight.data, std=0.2)\n",
    "        init.normal_(m.bias.data, std=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
    "                in_channels=100,\n",
    "                out_channels=64 * 8,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
    "                in_channels=64 * 8,\n",
    "                out_channels=64 * 4,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.deconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
    "                in_channels=64 * 4,\n",
    "                out_channels=64 * 2,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.deconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
    "                in_channels=64 * 2,\n",
    "                out_channels=64 * 1,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.deconv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 1, K1, S1, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.deconv4(x)\n",
    "        x = self.deconv5(x)\n",
    "        return x\n",
    " \n",
    " \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "                \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(  # batchsize,1,96,96\n",
    "                in_channels=1,\n",
    "                out_channels=64,\n",
    "                kernel_size=K1,\n",
    "                padding=1,\n",
    "                stride=S1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, inplace=True),\n",
    " \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False, ),  # batchsize,16,32,32\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(.2, inplace=True),\n",
    " \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(.2, inplace=True),\n",
    " \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(.2, inplace=True),\n",
    " \n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()  #\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_imgs\n"
     ]
    }
   ],
   "source": [
    "g = Generator().cuda()\n",
    "d = Discriminator().cuda()\n",
    " \n",
    "init_ws_bs(g), init_ws_bs(d)\n",
    " \n",
    "g_optimizer = torch.optim.Adam(g.parameters(), betas=(.5, 0.999), lr=G_LR)\n",
    "d_optimizer = torch.optim.Adam(d.parameters(), betas=(.5, 0.999), lr=D_LR)\n",
    " \n",
    "g_loss_func = nn.BCELoss()\n",
    "d_loss_func = nn.BCELoss()\n",
    " \n",
    "label_real = torch.ones(BATCHSIZE).cuda()\n",
    "label_fake = torch.zeros(BATCHSIZE).cuda()\n",
    "\n",
    "real_img = get_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 59 0.0026599357 16.558338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 119 0.00087071507 16.093792\n",
      "0 179 0.0033105134 17.931475\n",
      "0 239 0.026379757 20.857218\n",
      "0 299 0.016292412 20.035498\n",
      "0 359 0.0025174045 19.365269\n",
      "0 419 0.0007985751 18.418428\n",
      "0 479 0.0044573806 17.745872\n",
      "0 539 0.000894839 18.692402\n",
      "200 59 0.00041018362 9.368069\n",
      "200 119 0.0038076877 8.7699585\n",
      "200 179 0.00046522258 9.186563\n",
      "200 239 0.0013894469 9.141986\n",
      "200 299 0.00030700106 9.447865\n",
      "200 359 0.0007426002 8.688296\n",
      "200 419 0.0016714488 7.842141\n",
      "200 479 0.0017305925 6.780424\n",
      "200 539 0.0018386698 7.428142\n",
      "400 59 0.0013442208 26.084433\n",
      "400 119 0.01496202 16.088007\n",
      "400 179 1.8170633e-05 10.479563\n",
      "400 239 0.0066532195 19.000536\n",
      "400 299 7.751847e-06 19.022911\n",
      "400 359 0.0024441434 16.865248\n",
      "400 419 2.9286161e-06 15.1261635\n",
      "400 479 4.0404408e-05 10.420789\n",
      "400 539 0.0010903376 12.481567\n",
      "600 59 8.066552e-07 18.211203\n",
      "600 119 3.8018209e-06 24.200615\n",
      "600 179 2.4934639e-07 27.087065\n",
      "600 239 9.551416e-06 20.192785\n",
      "600 299 0.00015002918 28.308939\n",
      "600 359 0.0004644251 22.204851\n",
      "600 419 1.2547292e-05 14.721183\n",
      "600 479 0.00033984912 24.200838\n",
      "600 539 3.6628455e-06 26.884958\n",
      "800 59 5.6105087e-05 25.246857\n",
      "800 119 5.304869e-07 29.988005\n",
      "800 179 0.068386175 18.33626\n",
      "800 239 0.00012581298 10.414126\n",
      "800 299 0.022798201 21.727425\n",
      "800 359 3.4494886e-05 23.536991\n",
      "800 419 1.0033458e-07 24.423418\n",
      "800 479 1.4076709e-06 25.023064\n",
      "800 539 2.3742544e-07 23.436466\n",
      "1000 59 1.3907751e-08 19.622133\n",
      "1000 119 1.9868216e-09 21.615637\n",
      "1000 179 3.7749608e-08 21.52786\n",
      "1000 239 1.9868216e-09 20.768982\n",
      "1000 299 0.0 20.499735\n",
      "1000 359 1.8874804e-08 20.31441\n",
      "1000 419 6.755194e-08 21.495813\n",
      "1000 479 0.0 23.919779\n",
      "1000 539 1.5666768e-06 13.600751\n",
      "1200 59 0.001009662 39.342323\n",
      "1200 119 1.7881396e-08 46.968864\n",
      "1200 179 4.445835e-06 50.84756\n",
      "1200 239 0.00011403391 50.01988\n",
      "1200 299 0.10273485 40.961147\n",
      "1200 359 1.9868218e-09 31.436108\n",
      "1200 419 4.178434e-06 24.863255\n",
      "1200 479 0.00042774668 17.863363\n",
      "1200 539 0.31265467 34.201275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-be3a3b7f67e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0md_real_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mbatch_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCHSIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m#batch_fake = dataset[start:end].cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mimg_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHES):\n",
    "    np.random.shuffle(real_img)\n",
    "    count = 0\n",
    "    generate=0\n",
    "    batch_imgs = []\n",
    "    \n",
    "    if epoch > 200:\n",
    "        g_optimizer = torch.optim.Adam(g.parameters(), betas=(.5, 0.999), lr=0.8*G_LR)\n",
    "        d_optimizer = torch.optim.Adam(d.parameters(), betas=(.5, 0.999), lr=0.8*D_LR)\n",
    "        \n",
    "    if epoch > 500:\n",
    "        g_optimizer = torch.optim.Adam(g.parameters(), betas=(.5, 0.999), lr=0.5*G_LR)\n",
    "        d_optimizer = torch.optim.Adam(d.parameters(), betas=(.5, 0.999), lr=0.5*D_LR)\n",
    "       \n",
    "    for i in range(len(real_img)):\n",
    "        count = count + 1\n",
    "        batch_imgs.append(real_img[i])  # tensor类型#这里经过trans操作通道维度从第四个到第二个了\n",
    "        if count % BATCHSIZE==0:\n",
    "            #count = 0\n",
    "            start=count-BATCHSIZE\n",
    "            end=count\n",
    "                         \n",
    "            batch_real = torch.Tensor(batch_imgs).cuda()\n",
    "            batch_imgs.clear()\n",
    "            d_optimizer.zero_grad()\n",
    "            pre_real = d(batch_real.unsqueeze(1)).squeeze()\n",
    "            d_real_loss = d_loss_func(pre_real, label_real)\n",
    "            d_real_loss.backward()\n",
    " \n",
    "            batch_fake = torch.randn(BATCHSIZE, 100, 1, 1).cuda()\n",
    "            #batch_fake = dataset[start:end].cuda()\n",
    "            img_fake = g(batch_fake).detach()\n",
    "            pre_fake = d(img_fake).squeeze()\n",
    "\n",
    "            d_fake_loss = d_loss_func(pre_fake, label_fake)\n",
    "            d_fake_loss.backward()\n",
    " \n",
    "            d_optimizer.step()\n",
    " \n",
    "            g_optimizer.zero_grad()\n",
    "            batch_fake = torch.randn(BATCHSIZE, 100, 1, 1).cuda()\n",
    "            #batch_fake = dataset[start:end].cuda()\n",
    "            img_fake = g(batch_fake)\n",
    "            pre_fake = d(img_fake).squeeze()\n",
    "                            \n",
    "            g_loss = g_loss_func(pre_fake, label_real)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if epoch>=200:\n",
    "                generate=generate+1\n",
    "                imgs=g(torch.randn(1,100,1,1).cuda())                \n",
    "                image=imgs[0].permute(1,2,0).cpu().detach().numpy()*255\n",
    "                cv2.imwrite(\"test_samples/\"+str(epoch)+str(generate)+\".jpg\",image)\n",
    "            \n",
    "            if epoch%200==0:\n",
    "                print(epoch,i,(d_real_loss + d_fake_loss).detach().cpu().numpy(), g_loss.detach().cpu().numpy())\n",
    "                torch.save(g, \"pkl/\" + str(epoch) + \"g.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
